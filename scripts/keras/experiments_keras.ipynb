{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from ae_keras import ReflectionPadding1D, IncrFeatStridedConvFCUpsampReflectPadAE\n",
    "import torch\n",
    "\n",
    "from dipy.io.stateful_tractogram import Space\n",
    "from dipy.io.streamline import load_tractogram\n",
    "from dipy.tracking.streamline import Streamlines  # same as nibabel.streamlines.ArraySequence\n",
    "\n",
    "import aux_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of streamlines: 3112\n",
      "Example of a streamline: [-62.621086  -17.029413    2.6032662]\n",
      "N of points in the first streamline: 256\n"
     ]
    }
   ],
   "source": [
    "# Read some TRK data:\n",
    "fibercup_path = \"/home/teitxe/data/FiberCup/\"\n",
    "data_path = \"/home/teitxe/data/FiberCup/fibercup_advanced_filtering_no_ushapes/\"\n",
    "f_trk_data = op.join(data_path, \"ae_input_std_endpoints/train/fibercup_Simulated_prob_tracking_minL10_resampled256_plausibles_std_endpoints_train.trk\")\n",
    "f_img_data = op.join(fibercup_path, \"Simulated_FiberCup.nii.gz\")\n",
    "streamlines = af.read_data(f_trk_data, f_img_data)\n",
    "print(f\"N of streamlines: {len(streamlines)}\")\n",
    "print(f\"Example of a streamline: {streamlines[0][0]}\")\n",
    "print(f\"N of points in the first streamline: {len(streamlines[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between input and output for a streamline point = [-62.62566   -16.969572    2.5094502]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Model\n",
    "latent_space_dims = 32\n",
    "model = IncrFeatStridedConvFCUpsampReflectPadAE(latent_space_dims)\n",
    "input_shape = (1, 256, 3)  # Example input shape\n",
    "input_streamline = np.array([streamlines[0]])\n",
    "output = model.call(input_streamline)\n",
    "\n",
    "print(f\"Difference between input and output for a streamline point = {(input_streamline - output)[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset to fetch from it during the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tensorflow dataset out of the streamlines\n",
    "dataset = tf.data.Dataset.from_tensor_slices(streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Loss and the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: Mean squared error\n",
    "loss_mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return loss_mse(y_true=y, y_pred=y_)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset_train_batch:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m grad(model, x, x)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Track progress\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     epoch_mse\u001b[38;5;241m.\u001b[39mupdate_state(x, model(x))\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:282\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    281\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:351\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:405\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    396\u001b[0m     ops\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    397\u001b[0m         is_update_step,\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: _update_step_fn(grads, trainable_variables),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m         ),\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    412\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:119\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backend_update_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads, trainable_variables, learning_rate):\n\u001b[1;32m    115\u001b[0m     trainable_variables \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    116\u001b[0m         v\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, backend\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trainable_variables\n\u001b[1;32m    118\u001b[0m     ]\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:135\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:132\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/optimizers/adadelta.py:120\u001b[0m, in \u001b[0;36mAdadelta.update_step\u001b[0;34m(self, grad, variable, learning_rate)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m    105\u001b[0m     accumulated_grad,\n\u001b[1;32m    106\u001b[0m     ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    107\u001b[0m         rho \u001b[38;5;241m*\u001b[39m accumulated_grad, ops\u001b[38;5;241m.\u001b[39mmultiply(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m rho, ops\u001b[38;5;241m.\u001b[39msquare(grad))\n\u001b[1;32m    108\u001b[0m     ),\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    110\u001b[0m delta_var \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mnegative(\n\u001b[1;32m    111\u001b[0m     ops\u001b[38;5;241m.\u001b[39mdivide(\n\u001b[1;32m    112\u001b[0m         ops\u001b[38;5;241m.\u001b[39mmultiply(rms(accumulated_delta_var), grad),\n\u001b[1;32m    113\u001b[0m         rms(accumulated_grad),\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m    117\u001b[0m     accumulated_delta_var,\n\u001b[1;32m    118\u001b[0m     ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    119\u001b[0m         ops\u001b[38;5;241m.\u001b[39mmultiply(rho, accumulated_delta_var),\n\u001b[0;32m--> 120\u001b[0m         ops\u001b[38;5;241m.\u001b[39mmultiply(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m rho, \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta_var\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    121\u001b[0m     ),\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_add(variable, ops\u001b[38;5;241m.\u001b[39mmultiply(lr, delta_var))\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/ops/numpy.py:5652\u001b[0m, in \u001b[0;36msquare\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   5642\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.square\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.numpy.square\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msquare\u001b[39m(x):\n\u001b[1;32m   5644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the element-wise square of the input.\u001b[39;00m\n\u001b[1;32m   5645\u001b[0m \n\u001b[1;32m   5646\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5650\u001b[0m \u001b[38;5;124;03m        Output tensor, the square of `x`.\u001b[39;00m\n\u001b[1;32m   5651\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43many_symbolic_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   5653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Square()\u001b[38;5;241m.\u001b[39msymbolic_call(x)\n\u001b[1;32m   5654\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39msquare(x)\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:297\u001b[0m, in \u001b[0;36many_symbolic_tensors\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten((args, kwargs)):\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKerasTensor\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_mse_results = []\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 1\n",
    "dataset_train_batch = dataset.batch(batch_size)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_mse = tf.keras.metrics.MeanSquaredError()\n",
    "    \n",
    "    for x in dataset_train_batch:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, x)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # Track progress\n",
    "        epoch_mse.update_state(x, model(x))\n",
    "    \n",
    "    # End epoch\n",
    "    train_mse_results.append(epoch_mse.result())\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss: {epoch_mse.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(256, 3), dtype=float32). Expected shape (1, 256, 3), but input has incompatible shape (256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(256, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/tractolearn/.env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/projects/tractolearn/scripts/keras/ae_keras.py:111\u001b[0m, in \u001b[0;36mIncrFeatStridedConvFCUpsampReflectPadAE.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 111\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(encoded)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoded\n",
      "File \u001b[0;32m~/projects/tractolearn/scripts/keras/ae_keras.py:77\u001b[0m, in \u001b[0;36mIncrFeatStridedConvFCUpsampReflectPadAE.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 77\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencod_conv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     78\u001b[0m     h2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencod_conv2(h1))\n\u001b[1;32m     79\u001b[0m     h3 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencod_conv3(h2))\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(256, 3), dtype=float32). Expected shape (1, 256, 3), but input has incompatible shape (256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(256, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a training loop iteration manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 6098.486328125\n",
      "Step: 0,         Loss: 6098.486328125\n"
     ]
    }
   ],
   "source": [
    "loss_value, gradients = grad(model, input_streamline, input_streamline)\n",
    "print(f\"Step: {optimizer.iterations.numpy()}, Initial Loss: {loss_value.numpy()}\")\n",
    "print(f\"Step: {optimizer.iterations.numpy()},         Loss: {loss(model, input_streamline, input_streamline).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a leading underscore to avoid function parameters shadowing these\n",
    "# variables\n",
    "_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "_train_tractogram_fname = \"strml_train.trk\"\n",
    "_valid_tractogram_fname = \"strml_valid.trk\"\n",
    "_img_fname = \"t1.nii.gz\"\n",
    "_trained_weights_fname = \"already_available_model_weights.pt\"\n",
    "_training_weights_fname = \"training_model_weights.pt\"\n",
    "# The following values were found to give best results\n",
    "_lr = 6.68e-4\n",
    "_weight_decay = 0.13\n",
    "_epochs = 100\n",
    "# resample_data()   # resample your tractogram to 256 points if needed\n",
    "test_ae_model(\n",
    "    _train_tractogram_fname, _img_fname, _device\n",
    ")  # only does a forward pass, does not train the model\n",
    "test_ae_model_loader(_train_tractogram_fname, _img_fname, _device)  # computes loss\n",
    "_ = load_model_weights(_trained_weights_fname, _device, _lr, _weight_decay)  # load model weights\n",
    "train_ae_model(\n",
    "    _train_tractogram_fname, _valid_tractogram_fname, _img_fname, _device, _lr, _weight_decay, _epochs, _training_weights_fname\n",
    ")  # computes loss and trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to export the model weights from PyTorch ---> ONNX ---> TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tractolearn.models.track_ae_cnn1d_incr_feat_strided_conv_fc_upsamp_reflect_pad_pytorch as AE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0901, 0.0901], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = \"/home/teitxe/data/tractolearn_data/\"\n",
    "state_dict = torch.load(os.path.join(weights_path, \"best_model_contrastive_tractoinferno_hcp.pt\"), map_location=torch.device('cpu'))\n",
    "net = AE_model.IncrFeatStridedConvFCUpsampReflectPadAE(32)\n",
    "dummy_input = torch.randn(1, 3, 256)\n",
    "net(dummy_input)[0][0][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the weights into the model and export them to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/teitxe/projects/tractolearn/.env/lib/python3.10/site-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(state_dict[\"state_dict\"])\n",
    "onnx_file = os.path.join(weights_path, \"best_model_contrastive_tractoinferno_hcp.onnx\")\n",
    "torch.onnx.export(net, dummy_input, onnx_file, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm -v /home/teitxe:/workdir -w /workdir docker.io/pinto0309/onnx2tf:1.22.3 /bin/bash -c \"mkdir -p /workdir/data/tractolearn_data/tf_model && onnx2tf -i /workdir/data/tractolearn_data/best_model_contrastive_tractoinferno_hcp.onnx -o /workdir/data/tractolearn_data/tf_model\"\n",
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "Simplifying...\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃            ┃ Original Model ┃ Simplified Model ┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Constant   │ 32             │ 32               │\n",
      "│ Conv       │ 12             │ 12               │\n",
      "│ Gemm       │ 2              │ 2                │\n",
      "│ Pad        │ 12             │ 12               │\n",
      "│ Relu       │ 10             │ 10               │\n",
      "│ Reshape    │ 2              │ 2                │\n",
      "│ Resize     │ 5              │ 5                │\n",
      "│ Model Size │ 18.0MiB        │ 18.0MiB          │\n",
      "└────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying...\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃            ┃ Original Model ┃ Simplified Model ┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Constant   │ 32             │ 32               │\n",
      "│ Conv       │ 12             │ 12               │\n",
      "│ Gemm       │ 2              │ 2                │\n",
      "│ Pad        │ 12             │ 12               │\n",
      "│ Relu       │ 10             │ 10               │\n",
      "│ Reshape    │ 2              │ 2                │\n",
      "│ Resize     │ 5              │ 5                │\n",
      "│ Model Size │ 18.0MiB        │ 18.0MiB          │\n",
      "└────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying...\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃            ┃ Original Model ┃ Simplified Model ┃\n",
      "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Constant   │ 32             │ 32               │\n",
      "│ Conv       │ 12             │ 12               │\n",
      "│ Gemm       │ 2              │ 2                │\n",
      "│ Pad        │ 12             │ 12               │\n",
      "│ Relu       │ 10             │ 10               │\n",
      "│ Reshape    │ 2              │ 2                │\n",
      "│ Resize     │ 5              │ 5                │\n",
      "│ Model Size │ 18.0MiB        │ 18.0MiB          │\n",
      "└────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "\u001b[32mModel optimizing complete!\u001b[0m\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 3, 256] \u001b[32mdtype\u001b[0m: float32\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /encod_conv1/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 3, 256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: [6] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv1/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 3, 258] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: input \u001b[34mshape\u001b[0m: (1, 256, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad//encod_conv1/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 258, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /encod_conv1/encod_conv1.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv1/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 3, 258] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: encod_conv1.1.weight \u001b[36mshape\u001b[0m: [32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: encod_conv1.1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv1/encod_conv1.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad//encod_conv1/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 258, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv1/encod_conv1.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /encod_conv2/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv2/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 32, 130] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1//encod_conv2/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 130, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /encod_conv2/encod_conv2.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv2/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 32, 130] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: encod_conv2.1.weight \u001b[36mshape\u001b[0m: [64, 32, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: encod_conv2.1.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv2/encod_conv2.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1//encod_conv2/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 130, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 32, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv2/encod_conv2.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /encod_conv3/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv3/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 64, 66] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2//encod_conv3/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 66, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /encod_conv3/encod_conv3.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv3/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 64, 66] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: encod_conv3.1.weight \u001b[36mshape\u001b[0m: [128, 64, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: encod_conv3.1.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv3/encod_conv3.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2//encod_conv3/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 66, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 64, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv3/encod_conv3.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /encod_conv4/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_2_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv4/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 128, 34] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3//encod_conv4/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 34, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /encod_conv4/encod_conv4.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv4/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 128, 34] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: encod_conv4.1.weight \u001b[36mshape\u001b[0m: [256, 128, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: encod_conv4.1.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv4/encod_conv4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3//encod_conv4/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 34, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 128, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_3\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv4/encod_conv4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_3_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /encod_conv5/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_3_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv5/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 256, 18] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_4//encod_conv5/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 18, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /encod_conv5/encod_conv5.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv5/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 256, 18] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: encod_conv5.1.weight \u001b[36mshape\u001b[0m: [512, 256, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: encod_conv5.1.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv5/encod_conv5.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_4//encod_conv5/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 18, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 256, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_4\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv5/encod_conv5.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_4_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /encod_conv6/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_4_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv6/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 512, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_5//encod_conv6/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 10, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /encod_conv6/encod_conv6.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv6/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 512, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: encod_conv6.1.weight \u001b[36mshape\u001b[0m: [1024, 512, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: encod_conv6.1.bias \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /encod_conv6/encod_conv6.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_5//encod_conv6/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 10, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 512, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 8, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /Reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /encod_conv6/encod_conv6.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Concat_output_0 \u001b[36mshape\u001b[0m: [2] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Reshape_output_0 \u001b[36mshape\u001b[0m: [1, 8192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_2/transpose:0 \u001b[34mshape\u001b[0m: (1, 1024, 8) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 8192] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (1, 8192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /fc1/Gemm\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Reshape_output_0 \u001b[36mshape\u001b[0m: [1, 8192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: fc1.weight \u001b[36mshape\u001b[0m: [32, 8192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: fc1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /fc1/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 8192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (8192, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /fc2/Gemm\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc1/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: fc2.weight \u001b[36mshape\u001b[0m: [8192, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: fc2.bias \u001b[36mshape\u001b[0m: [8192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /fc2/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 8192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (32, 8192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (8192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (1, 8192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /Reshape_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc2/Gemm_output_0 \u001b[36mshape\u001b[0m: [1, 8192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Concat_1_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Reshape_1_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (1, 8192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 1024, 8] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_3/Reshape:0 \u001b[34mshape\u001b[0m: (1, 1024, 8) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /decod_conv1/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Reshape_1_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv1/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_3/Reshape:0 \u001b[34mshape\u001b[0m: (1, 1024, 8) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_6//decod_conv1/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 1024, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /decod_conv1/decod_conv1.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv1/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 1024, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: decod_conv1.1.weight \u001b[36mshape\u001b[0m: [512, 1024, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: decod_conv1.1.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv1/decod_conv1.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_7/transpose:0 \u001b[34mshape\u001b[0m: (1, 10, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 1024, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_5\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv1/decod_conv1.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_5_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: /upsampl1/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_5_output_0 \u001b[36mshape\u001b[0m: [1, 512, 8] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /upsampl1/Constant_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /upsampl1/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 512, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.expand_dims_7/ExpandDims:0 \u001b[34mshape\u001b[0m: (1, 1, 8, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mval\u001b[0m: [512, 16] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 16, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m27 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /decod_conv2/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /upsampl1/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 512, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv2/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 512, 18] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 16, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_7//decod_conv2/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 18, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m28 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /decod_conv2/decod_conv2.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv2/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 512, 18] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: decod_conv2.1.weight \u001b[36mshape\u001b[0m: [256, 512, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: decod_conv2.1.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv2/decod_conv2.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_7//decod_conv2/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 18, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 512, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m29 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv2/decod_conv2.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_6_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m30 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: /upsampl2/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_6_output_0 \u001b[36mshape\u001b[0m: [1, 256, 16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /upsampl1/Constant_output_0 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /upsampl2/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 256, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.expand_dims_9/ExpandDims:0 \u001b[34mshape\u001b[0m: (1, 1, 16, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mval\u001b[0m: [256, 32] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_1/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 32, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m31 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /decod_conv3/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /upsampl2/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 256, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv3/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 256, 34] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_1/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 32, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_8//decod_conv3/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 34, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m32 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /decod_conv3/decod_conv3.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv3/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 256, 34] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: decod_conv3.1.weight \u001b[36mshape\u001b[0m: [128, 256, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: decod_conv3.1.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv3/decod_conv3.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_8//decod_conv3/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 34, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 256, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m33 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_7\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv3/decod_conv3.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_7_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m34 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: /upsampl3/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_7_output_0 \u001b[36mshape\u001b[0m: [1, 128, 32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /upsampl1/Constant_output_0 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /upsampl3/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 128, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.expand_dims_11/ExpandDims:0 \u001b[34mshape\u001b[0m: (1, 1, 32, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mval\u001b[0m: [128, 64] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_2/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 64, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m35 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /decod_conv4/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /upsampl3/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 128, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv4/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 128, 66] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_2/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 64, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_9//decod_conv4/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 66, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m36 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /decod_conv4/decod_conv4.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv4/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 128, 66] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: decod_conv4.1.weight \u001b[36mshape\u001b[0m: [64, 128, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: decod_conv4.1.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv4/decod_conv4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_9//decod_conv4/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 66, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m37 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_8\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv4/decod_conv4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_8_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m38 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: /upsampl4/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_8_output_0 \u001b[36mshape\u001b[0m: [1, 64, 64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /upsampl1/Constant_output_0 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /upsampl4/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 64, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.expand_dims_13/ExpandDims:0 \u001b[34mshape\u001b[0m: (1, 1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mval\u001b[0m: [64, 128] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_3/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m39 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /decod_conv5/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /upsampl4/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 64, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv5/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 64, 130] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_3/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 128, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_10//decod_conv5/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 130, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m40 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /decod_conv5/decod_conv5.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv5/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 64, 130] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: decod_conv5.1.weight \u001b[36mshape\u001b[0m: [32, 64, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: decod_conv5.1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv5/decod_conv5.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_10//decod_conv5/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 130, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 64, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m41 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /Relu_9\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv5/decod_conv5.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Relu_9_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m42 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: /upsampl5/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Relu_9_output_0 \u001b[36mshape\u001b[0m: [1, 32, 128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /upsampl1/Constant_output_0 \u001b[36mshape\u001b[0m: (3,) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /upsampl5/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 32, 256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.expand_dims_15/ExpandDims:0 \u001b[34mshape\u001b[0m: (1, 1, 128, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mval\u001b[0m: [32, 256] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_4/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 256, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m43 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Pad\u001b[35m onnx_op_name\u001b[0m: /decod_conv6/pad/Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /upsampl5/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 32, 256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /encod_conv1/pad/Reshape_1_output_0 \u001b[36mshape\u001b[0m: (6,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /decod_conv6/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 32, 258] \u001b[36mdtype\u001b[0m: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1716981887.040676       1 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1716981887.040735       1 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "W0000 00:00:1716981887.460485       1 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1716981887.460539       1 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: Pad\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.gather_4/GatherV2:0 \u001b[34mshape\u001b[0m: (1, 256, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.paddings\u001b[0m: \u001b[34mshape\u001b[0m: (3, 2) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.constant_value\u001b[0m: \u001b[34mval\u001b[0m: 0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.mode\u001b[0m: \u001b[34mval\u001b[0m: reflect \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.tensor_rank\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_11//decod_conv6/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 258, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m44 / 44\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /decod_conv6/decod_conv6.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /decod_conv6/pad/Pad_output_0 \u001b[36mshape\u001b[0m: [1, 32, 258] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: decod_conv6.1.weight \u001b[36mshape\u001b[0m: [3, 32, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: decod_conv6.1.bias \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output \u001b[36mshape\u001b[0m: [1, 3, 256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_11//decod_conv6/pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 258, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 32, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (3,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 256, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='docker run --rm -v /home/teitxe:/workdir -w /workdir docker.io/pinto0309/onnx2tf:1.22.3 /bin/bash -c \"mkdir -p /workdir/data/tractolearn_data/tf_model && onnx2tf -i /workdir/data/tractolearn_data/best_model_contrastive_tractoinferno_hcp.onnx -o /workdir/data/tractolearn_data/tf_model\"', returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "container = 'docker run --rm -v /home/teitxe:/workdir -w /workdir docker.io/pinto0309/onnx2tf:1.22.3 /bin/bash -c \"'\n",
    "tf_model_path = '/workdir/data/tractolearn_data/tf_model'\n",
    "onnx_model_path = '/workdir/data/tractolearn_data/best_model_contrastive_tractoinferno_hcp.onnx'\n",
    "command = f'mkdir -p {tf_model_path} && onnx2tf -i {onnx_model_path} -o {tf_model_path}\"'\n",
    "print(container + command)\n",
    "sp.run(container + command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to load the model into TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_tf_model_path = '/home/teitxe/data/tractolearn_data/tf_model'\n",
    "imported = tf.saved_model.load(local_tf_model_path)\n",
    "f = imported.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
